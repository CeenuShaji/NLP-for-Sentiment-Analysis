{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e31e274",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, TFBertForSequenceClassification\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample, InputFeatures\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset found at https://www.kaggle.com/datasets/harshalhonde/starbucks-reviews-dataset?resource=download\n",
    "df = pd.read_csv('reviews_data.csv')\n",
    "# Assume 'reviews' column contains the text and 'stars' column contains ratings\n",
    "\n",
    "# Convert ratings to binary sentiment labels\n",
    "df['sentiment'] = df['stars'].apply(lambda x: 1 if x > 3 else 0)\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the text\n",
    "def convert_example_to_feature(review):\n",
    "    return tokenizer.encode_plus(review, \n",
    "                                 add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "                                 max_length=512,  # Max length to truncate/pad\n",
    "                                 pad_to_max_length=True,  # Pad sentence to max length\n",
    "                                 return_attention_mask=True,  # Return attention mask\n",
    "                                )\n",
    "\n",
    "# Map the tokenizer function to reviews\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for review in df['reviews']:\n",
    "    encoded_review = convert_example_to_feature(review)\n",
    "    input_ids.append(encoded_review['input_ids'])\n",
    "    attention_masks.append(encoded_review['attention_mask'])\n",
    "\n",
    "input_ids = np.array(input_ids)\n",
    "attention_masks = np.array(attention_masks)\n",
    "labels = df['sentiment'].values\n",
    "\n",
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=2018, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2018, test_size=0.1)\n",
    "\n",
    "# Load the pre-trained BERT model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "# Train the model\n",
    "model.fit([train_inputs, train_masks], train_labels, batch_size=32, epochs=2, validation_data=([validation_inputs, validation_masks], validation_labels))\n",
    "\n",
    "# Note: This code is simplified for illustrative purposes and may require adjustments based on the specific details of the Starbucks Reviews Dataset, such as handling very large datasets or optimizing model parameters for better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a8e80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
